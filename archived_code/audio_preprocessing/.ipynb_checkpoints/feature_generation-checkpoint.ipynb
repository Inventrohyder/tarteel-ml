{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "A file for preprocessing audio recordings from tarteel.io for input into\n",
    "TensorFlow models.\n",
    "\n",
    "Filter bank and MFCC background referenced from\n",
    "[1] https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html\n",
    "and\n",
    "http://www.practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/.\n",
    "\n",
    "Tensorflow implementation details inspired by API at\n",
    "https://www.tensorflow.org/api_guides/python/contrib.signal.\n",
    "\n",
    "Author: Hamzah Khan\n",
    "Date: Jan. 12, 2019\n",
    "\"\"\"\n",
    "# Argument constants.\n",
    "ALL_SURAHS = 0\n",
    "NUM_SURAHS = 114\n",
    "\n",
    "OUTPUT_MFCC = \"mfcc\"\n",
    "OUTPUT_MEL_FILTER_BANK = \"mel_filter_bank\"\n",
    "OUTPUT_LOG_MEL_FILTER_BANK = \"log_mel_filter_bank\"\n",
    "\n",
    "# Define constants.\n",
    "\n",
    "# Unsupported sampling frequencies.\n",
    "SUPPORTED_FREQUENCIES = [8000, 16000, 32000, 48000]\n",
    "\n",
    "# Select a pre_emphasis coefficient. \n",
    "\"\"\"\n",
    "Typical values for the [pre-emphasis] filter coefficient are 0.95 or 0.97.\n",
    "\"\"\"\n",
    "pre_emphasis_factor_1 = 0.95\n",
    "pre_emphasis_factor_2 = 0.97\n",
    "PRE_EMPHASIS_FACTOR = pre_emphasis_factor_1\n",
    "\n",
    "# Select the frame splitting constants. Note that frames can and should overlap.\n",
    "\"\"\"\n",
    "\"Typical frame sizes in speech processing range from 20 ms to 40 ms with 50% (+/-10%) overlap between consecutive\n",
    "frames. Popular settings are 25 ms for the frame size, frame_size = 0.025 and a 10 ms stride (15 ms overlap),\n",
    "frame_stride = 0.01\" [1].\n",
    "\"\"\"\n",
    "FRAME_SIZE_S = 0.025\n",
    "FRAME_STRIDE_S = 0.01\n",
    "\n",
    "\"\"\"\n",
    "For the \"Short-Time Fourier-Transform (STFT) (over N points),... N is typically 256 or 512.\" [1]\n",
    "\"\"\"\n",
    "# Select the number of points used in the Short-Time Fourier Transform.\n",
    "STFT_NUM_POINTS_1 = 256\n",
    "STFT_NUM_POINTS_2 = 512\n",
    "STFT_NUM_POINTS = STFT_NUM_POINTS_2\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\"typically 40 filters... The Mel-scale aims to mimic the non-linear human ear perception of sound,\n",
    "by being more discriminative at lower frequencies and less discriminative at higher frequencies.\n",
    "[1]\"\n",
    "\"\"\"\n",
    "# Select the number of triangular filters to apply to the power spectrum for frequency band extraction.\n",
    "NUM_TRIANGULAR_FILTERS = 40\n",
    "\n",
    "# Select the default number of mel-frequency cepstral coefficents to reduce to from filter banks. This number must be\n",
    "# less than the number of filters.\n",
    "NUM_MFCCS = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import recording_utils\n",
    "import scipy.io.wavfile\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.contrib import signal as tf_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function stft at 0xb3a4adf28>\n"
     ]
    }
   ],
   "source": [
    "print(tensorflow.contrib.signal.stft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 180224)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a03faaa831fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmel_spectrograms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagnitude_spectrograms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_to_mel_weight_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmel_spectrograms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/tarteel/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \"\"\"\n\u001b[0;32m--> 713\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tarteel/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5143\u001b[0;31m       raise ValueError(\"Cannot evaluate tensor using `eval()`: No default \"\n\u001b[0m\u001b[1;32m   5144\u001b[0m                        \u001b[0;34m\"session is registered. Use `with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5145\u001b[0m                        \u001b[0;34m\"sess.as_default()` or pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`"
     ]
    }
   ],
   "source": [
    "sample_rate_hz, signal_np = scipy.io.wavfile.read(\"../.audio/s1/a7/1_7_2212954817.wav\")\n",
    "signal = tf.convert_to_tensor(signal_np.transpose(), tf.float32)\n",
    "print(signal.shape)\n",
    "\n",
    "frames = tf.contrib.signal.frame(signal, frame_length=400, frame_step=100)\n",
    "\n",
    "stfts = tf_signal.stft(frames, frame_length=400, frame_step=100, fft_length=512, window_fn=tf.contrib.signal.hamming_window)\n",
    "\n",
    "magnitude_spectrograms = tf.abs(stfts)\n",
    "num_spectrogram_bins = 257\n",
    "\n",
    "# Compute the conversion matrix to mel-frequency space.\n",
    "linear_to_mel_weight_matrix = tf.contrib.signal.linear_to_mel_weight_matrix(num_mel_bins=40,\n",
    "                                                                            num_spectrogram_bins=num_spectrogram_bins,\n",
    "                                                                            sample_rate=sample_rate_hz,\n",
    "                                                                            lower_edge_hertz=80.0,\n",
    "                                                                            upper_edge_hertz=24000.00,\n",
    "                                                                            dtype=tf.float32)\n",
    "\n",
    "mel_spectrograms = tf.tensordot(magnitude_spectrograms, linear_to_mel_weight_matrix, 1)\n",
    "mel_spectrograms.set_shape(magnitude_spectrograms.shape[:-1].concatenate(linear_to_mel_weight_matrix.shape[-1:]))\n",
    "\n",
    "mel_spectrograms.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
